film %>%
filter(Studio=="Uni.") %>%
select(Rank) %>%
max()
film %>%
filter(Studio=="Uni.") %>%
select(Rank,Film) %>%
which.max()
film %>%
filter(Studio=="Uni.") %>%
select(Rank) %>%
which.max() %>%
film$Film[]
film %>%
filter(Studio=="Uni.") %>%
select(Rank) %>%
which.max()
film %>%
filter(Studio=="Uni.") %>%
select(Rank) %>%
max()
max <- film %>%
filter(Studio=="Uni.") %>%
select(Rank)
max
which.max(max$Rank)
film$Film[which.max(max$Rank)]
sort(film$Gross,decreasing=T)
gross <- sort(film$Gross,decreasing=T)
topGross <- gross[1:10,]
topGross <- gross[1:10]
topGross
gross <- sort(film, method="Gross", decreasing=T)
install.packages("tidyr")
library(tidyr)
sortedFilm <- arrange(film, desc(Gross))
topGross <- sortedFilm[1:10]
which.min(topGross$Rank)
topGross
sortedFilm <- arrange(film, desc(Gross))
topGross <- sortedFilm[1:10,]
which.min(topGross$Rank)
topGross
which.min(topGross$Rank)
max <- film %>%
filter(Studio=="Uni.") %>%
select(Rank)
film$Film[which.min(max$Rank)]
top10 <- sortedFilm[1:10,]
which.min(topGross$Gross)
topGross[minIMDB,"Film"]
top10 <- sortedFilm[1:10,]
minIMDB <- which.min(top10$Gross)
top10[minIMDB,"Film"]
sortedFilm <- arrange(film, desc(Gross))
top10 <- sortedFilm[1:10,]
minIMDB <- which.min(top10$IMDB)
top10[minIMDB,"Film"]
min(top10$IMDB)
uniStu <- film %>%
filter(Studio=="Uni.")
which.max(uniStu$Rank)
uniStu[27,"Film"]
which.min(uniStu$Rank)
uniStu <- film %>%
filter(Studio=="Uni.")
which.min(uniStu$Rank)
uniStu[27,"Film"]
highest <- which.min(uniStu$Rank)
uniStu[highest,"Film"]
sortedFilm <- arrange(film, desc(Gross))
top10 <- sortedFilm[1:10,]
min(top10$IMDB)
View(uniStu)
View(sortedFilm)
sortedFilm <- arrange(film, desc(Rank))
# Subset the data to get the top 10 films
top10 <- sortedFilm[1:10,]
min(top10$IMDB)
View(sortedFilm)
sortedFilm <- arrange(film, asc(Rank))
sortedFilm <- arrange(film, Rank)
# Subset the data to get the top 10 films
top10 <- sortedFilm[1:10,]
min(top10$IMDB)
sortedFilms <- arrange(film, Rank)
# Subset the data to get the top 10 films
top10 <- sortedFilm[1:10,]
min(top10$IMDB)
View(sortedFilms)
sortedFilms <- arrange(film, Rank)
film <- FilmData
sortedFilms <- arrange(film, Rank)
# Subset the data to get the top 10 films
top10 <- sortedFilm[1:10,]
sortedFilms <- arrange(film, Rank)
# Subset the data to get the top 10 films
top10 <- sortedFilm[1:10,]
min(top10$IMDB)
top10 <- sortedFilm[1:10,]
sortedFilms <- arrange(film, Rank)
# Subset the data to get the top 10 films
top10 <- sortedFilms[1:10,]
min(top10$IMDB)
View(sortedFilms)
top10 <- sortedFilms[length(sortedFilms)-10:length(sortedFilms),]
min(top10$IMDB)
table(film$Rating)
aggregate(Budget~Rating,film,mean)
aggregate(Budget~Rating,film,sd)
boxplot(film$Budget~film$Rating, main= "Film Budgets by Rating",
ylab= "Budget", xlab= "MPAA Rating")
library(SDSFoundations)
library(dplyr)
film <- FilmData
View(film)
summary(film$Studio)
aggregate(Days~Studio, data=film, mean)
aggregate(Days~Studio, data=film, sd)
boxplot(film$Days~film$Studio,main="Days in studio difference",xlab="Studio",ylab="Days in studio")
dayModel <- aov(film$Days~film$Studio)
summary(dayModel)
TukeyHSD(dayModel)
summary(film$Gross.Dom)
summary(film$Gross.Dom/10000)
aggregate(Days~Studio, data=film, mean)
aggregate(Days~Studio, data=film, sd)
boxplot(film$Gross.Dom~film$Studio,main="Earnings by studio",xlab="Studio",ylab="Earnings")
aggregate(Gross.Dom~Studio, data=film, mean)
aggregate(Gross.Dom~Studio, data=film, sd)
aggregate(Pct.Dom~Studio, data=film, mean)
aggregate(Pct.Dom~Studio, data=film, sd)
boxplot(film$Pct.Dom~film$Studio,main="Earnings by studio",xlab="Studio",ylab="Earnings")
dayModel <- aov(film$Pct.Dom~film$Studio)
summary(dayModel)
pctModel <- aov(film$Pct.Dom~film$Studio)
TukeyHSD(dayModel)
TukeyHSD(pctModel)
pctModel <- aov(film$Pct.Dom~film$Studio)
summary(pctModel)
TukeyHSD(pctModel)
aggregate(Days~Studio, data=film, mean)
aggregate(Days~Studio, data=film, sd)
dayModel <- aov(film$Days~film$Studio)
summary(dayModel)
dayModel <- aov(film$Days~film$Studio)
summary(dayModel)
TukeyHSD(dayModel)
library(SDSFoundations)
library(dplyr)
film <- FilmData
high <- filter(Budget >= 150, film)
medium <- filter(Budget < 150 & Budget >= 100, film)
library(SDSFoundations)
library(dplyr)
film <- FilmData
high <- filter(Budget >= 150, film)
high <- filter(Budget >= 150, data=film)
high <- filter(film, Budget >= 150)
medium <- filter(film, Budget < 150 & Budget >= 100)
low <- filter(film, Budget < 100)
View(medium)
mean(high$Pct.Dom)
mean(medium$Pct.Dom)
mean(low$Pct.Dom)
grandMean <- (mean(high$Pct.Dom) + mean(medium$Pct.Dom) + mean(low$Pct.Dom))/3
grandMean
SSt <- sum(film$Pct.Dom^2)
SSt
SSt <- sum(film$Pct.Dom^2) - (sum(film$Pct.Dom)^2)/N
grandMean <- (mean(high$Pct.Dom) + mean(medium$Pct.Dom) + mean(low$Pct.Dom))/3
N <- 151
SSt <- sum(film$Pct.Dom^2) - (sum(film$Pct.Dom)^2)/N
SSt
means <- c(mean(high$Pct.Dom),mean(medium$Pct.Dom),mean(low$Pct.Dom))
grandMean <- means/3
grandMean <- sum(means)/3
means <- c(mean(high$Pct.Dom),mean(medium$Pct.Dom),mean(low$Pct.Dom))
grandMean <- sum(means)/3
sizes <- c(42,41,67)
for (i in 1:3) {
SSw <- sizes[i]*(means[i] - grandMean)^2
}
dfTotal <- N - 1
dfBetween <- 2
dfWithin <- N - 3
SSw = 0
for (i in 1:3) {
SSw = SSw + sizes[i]*(means[i] - grandMean)^2
}
dfTotal <- N - 1
dfBetween <- 2
dfWithin <- N - 3
SSb = SSt - SSw
MSw <- SSw/dfWithin
F_Stat <- MSb/MSw
MSb <- SSb/dfBetween
F_Stat <- MSb/MSw
SSt <- sum(film$Pct.Dom^2) - (sum(film$Pct.Dom)^2)/N
SSw = 0
for (i in 1:3) {
SSw = SSw + sizes[i]*(means[i] - grandMean)^2
}
dfTotal <- N - 1
dfBetween <- 2
dfWithin <- N - 3
SSb = SSt - SSw
MSb <- SSb/dfBetween
MSw <- SSw/dfWithin
F_Stat <- MSb/MSw
N <- 151
SSt <- sum(film$Pct.Dom^2) - (sum(film$Pct.Dom)^2)/N
SSw = 0
for (i in 1:3) {
SSw = SSw + sizes[i]*(means[i] - grandMean)^2
}
dfTotal <- N - 1
dfBetween <- 2
dfWithin <- N - 2
SSb = SSt - SSw
MSb <- SSb/dfBetween
MSw <- SSw/dfWithin
F_Stat <- MSb/MSw
film$Level <- rep(NA,151)
View(film)
library(SDSFoundations)
library(dplyr)
film <- FilmData
film$Level <- rep(NA,151)
for (i in 1:151) {
if (film$Budget >= 150) film[i,"Level"] <- "high"
else if (film$Budget < 150 & ) film[i,"Level"] <- "medium"
else if (film$Budget < 100) film[i,"Level"] <- "low"
for (i in 1:151) {
if (film[i,"Budget"] >= 150) film[i,"Level"] <- "high"
else if (film[i,"Budget"] < 150 & ) film[i,"Level"] <- "medium"
else film[i,"Level"] <- "low"
}
for (i in 1:151) {
if (film[i,"Budget"] >= 150) {film[i,"Level"] <- "high"}
else if (film[i,"Budget"] < 150 & ) {film[i,"Level"] <- "medium"}
else {film[i,"Level"] <- "low"}
}
for (i in 1:151) {
if (film[i,"Budget"] >= 150) {film[i,"Level"] <- "high"}
else if (film[i,"Budget"] < 150) {film[i,"Level"] <- "medium"}
else {film[i,"Level"] <- "low"}
}
for (i in 1:151) {
if (film[i,"Budget"] != NA) {
if (film[i,"Budget"] >= 150) {film[i,"Level"] <- "high"}
else if (film[i,"Budget"] < 150) {film[i,"Level"] <- "medium"}
else {film[i,"Level"] <- "low"}
}
}
for (i in 1:151) {
if (is.na(film[i,"Budget"]) == F) {
if (film[i,"Budget"] >= 150) {film[i,"Level"] <- "high"}
else if (film[i,"Budget"] < 150) {film[i,"Level"] <- "medium"}
else {film[i,"Level"] <- "low"}
}
}
View(film)
aggregate(Level~Budget,data=film)
aggregate(Level~Budget,data=film,mean)
warnings()
aggregate(Budget~Level,data=film,mean)
for (i in 1:151) {
if (is.na(film[i,"Budget"]) == F) {
if (film[i,"Budget"] >= 150) {film[i,"Level"] <- "high"}
else if (film[i,"Budget"] < 150 & film[i,"Budget"] >= 100) {film[i,"Level"] <- "medium"}
else {film[i,"Level"] <- "low"}
}
}
aggregate(Budget~Level,data=film,mean)
summary(film$Level)
table(film$Level)
aggregate(Pct.Dom~Level,data=film,mean)
pctModel <- aov(film$Pct.Dom~film$Level)
summary(pctModel)
TukeyHSD(pctModel)
boxplot(film$Budget~film$Level, main="Budget by levels", xlab="Levels", ylab="Million dollars")
qf(0.95,2,42)
5949.1 - 2387.7
SSw/42
3561.4/42
2387.7/2
1193.9/84.8
5949.1 - 2387.7
3561.4/42
letters <- read.csv("letters_ABPR.csv")
setwd("C:/Users/Tran/Desktop/MOOC/Edx/15.071x-The-Analytics-Edge/weekfour")
letters <- read.csv("letters_ABPR.csv")
letters$isB = as.factor(letters$letter == "B")
library(caTools)
set.seed(1000)
split <- sample.split(letters, SplitRatio = 0.5)
train <- letters[split==T,]
test <- letters[split==F,]
library(rpart)
library(rpart.plot)
treeModel <- rpart(isB ~. - letter, data=train, method="class")
predicts <- predict(treeModel, newdata=test, type="class")
table(test$isB,predicts)
library(randomForest)
forestModel <- randomForest(isB ~. - letter, data=train)
set.seed(1000)
forestModel <- randomForest(isB ~. - letter, data=train)
predictForest <- predict(forestModel, newdata=test)
table(test$isB,predictForest$isB)
table(test$isB,predictForest$isB)
table(test$isB,predictForest)
(1161+364)/1558
letters$letter = as.factor( letters$letter )
split <- sample.split(letters, SplitRatio=.5)
train <- letters[split==T,]
test <- letters[split==F,]
set.seed(2000)
split <- sample.split(letters, SplitRatio=.5)
train <- letters[split==T,]
test <- letters[split==F,]
table(test$isB)
1180/378
1180/1558
set.seed(2000)
split <- sample.split(letters$letter, SplitRatio=.5)
train <- letters[split==T,]
test <- letters[split==F,]
# What is the baseline accuracy on the testing set?
table(test$isB)
table(test)
View(test)
table(test$letter)
table(test$isB)
1175/1558
401/1558
treeModel <- rpart(letter ~. - isB, data=train, method="class")
treePredicts <- predict(treeModel, newdata=test, type="class")
table(test$letter, treePredicts)
348+318+363+340
1369/1558
forestModel <- randomForest(letter ~. - isB, newdata=test)
forestModel <- randomForest(letter~. - isB, newdata=test)
forestModel <- randomForest(letter~. - isB, data=test)
forestModel <- randomForest(letter~. - isB, data=train)
forestPredicts <- predict(forestModel, newdata=test)
table(test$letter, forestPredicts)
389+380+393+366
1528/1558
census <- read.csv("census.csv")
library(caTools)
set.seed(2000)
split <- sample.split(census, SplitRatio=0.6)
train <- census[split==T,]
test <- census[split==F,]
logisModel <- glm(Over50k~., data=train, family=binomial)
logisModel <- glm(over50k~., data=train, family=binomial)
View(census)
summary(logisModel)
convertedcensus <- census
census <- read.csv("census.csv")
library(caTools)
set.seed(2000)
convertedCensus <- census
convertedCensus$workclass <- as.character(convertedCensus$workclass)
convertedCensus$education <- as.character(convertedCensus$education)
convertedCensus$maritalstatus <- as.character(convertedCensus$maritalstatus)
convertedCensus$occupation <- as.character(convertedCensus$occupation)
convertedCensus$relationship <- as.character(convertedCensus$relationship)
convertedCensus$race <- as.character(convertedCensus$race)
convertedCensus$sex <- as.character(convertedCensus$sex)
convertedCensus$ <- as.character(convertedCensus$nativecountry)
split <- sample.split(convertedCensus, SplitRatio=0.6)
train <- convertedCensus[split==T,]
split <- sample.split(convertedCensus, SplitRatio=0.6)
train <- convertedCensus[split==T,]
test <- convertedCensus[split==F,]
logisModel <- glm(over50k~., data=train, family=binomial)
summary(logisModel)
census <- read.csv("census.csv")
library(caTools)
set.seed(2000)
convertedCensus <- census
convertedCensus$workclass <- as.character(convertedCensus$workclass)
convertedCensus$education <- as.character(convertedCensus$education)
convertedCensus$maritalstatus <- as.character(convertedCensus$maritalstatus)
convertedCensus$occupation <- as.character(convertedCensus$occupation)
convertedCensus$relationship <- as.character(convertedCensus$relationship)
convertedCensus$race <- as.character(convertedCensus$race)
convertedCensus$sex <- as.character(convertedCensus$sex)
convertedCensus$ <- as.character(convertedCensus$nativecountry)
split <- sample.split(convertedCensus, SplitRatio=0.6)
convertedCensus$nativecountry <- as.character(convertedCensus$nativecountry)
split <- sample.split(convertedCensus, SplitRatio=0.6)
train <- convertedCensus[split==T,]
test <- convertedCensus[split==F,]
logisModel <- glm(over50k~., data=train, family=binomial)
summary(logisModel)
str(convertedCensus)
logisModel <- glm(over50k~. - over50k, data=train, family=binomial)
summary(logisModel)
census <- read.csv("census.csv")
library(caTools)
set.seed(2000)
split <- sample.split(census, SplitRatio=0.6)
train <- census[split==T,]
test <- census[split==F,]
# Build a logistic regression model to predict the dependent variable "over50k",
# using all of the other variables in the dataset as independent variables.
logisModel <- glm(over50k~. - over50k, data=train, family=binomial)
summary(logisModel)
logisModel <- glm(over50k~. , data=train, family=binomial)
summary(logisModel)
census <- read.csv("census.csv")
library(caTools)
set.seed(2000)
split <- sample.split(census, SplitRatio=0.6)
train <- census[split==T,]
test <- census[split==F,]
# Build a logistic regression model to predict the dependent variable "over50k",
# using all of the other variables in the dataset as independent variables.
logisModel <- glm(over50k~. , data=train, family=binomial)
summary(logisModel)
logisPredicts <- predict(logisModel, newdata=test)
table(test$over50k, logisPredicts)
table(test$over50k, logisPredicts > 0.5)
table(test$over50k==T, logisPredicts > 0.5)
table(test$over50k, logisPredicts > 0.5)
table(test$over50k=="<=50K", logisPredicts > 0.5)
head(logisPredicts)
table(test$over50k, logisPredicts > 0.5)
10762+1700
12462/14760
table(test$over50k)
11198/14760
census <- read.csv("census.csv")
library(caTools)
set.seed(2000)
split <- sample.split(census, SplitRatio=0.6)
train <- census[split==T,]
test <- census[split==F,]
logisModel <- glm(over50k~. , data=train, family=binomial)
summary(logisModel)
logisPredicts <- predict(logisModel, newdata=test)
split <- sample.split(census$over50k, SplitRatio=0.6)
train <- census[split==T,]
test <- census[split==F,]
# Build a logistic regression model to predict the dependent variable "over50k",
# using all of the other variables in the dataset as independent variables.
logisModel <- glm(over50k~. , data=train, family=binomial)
summary(logisModel)
logisPredicts <- predict(logisModel, newdata=test)
table(test$over50k, logisPredicts > 0.5)
table(test$over50k)
census <- read.csv("census.csv")
library(caTools)
set.seed(2000)
split <- sample.split(census$over50k, SplitRatio=0.6)
train <- census[split==T,]
test <- census[split==F,]
# Build a logistic regression model to predict the dependent variable "over50k",
# using all of the other variables in the dataset as independent variables.
logisModel <- glm(over50k~. , data=train, family=binomial)
summary(logisModel)
table(test$over50k, logisPredicts > 0.5)
logisPredicts <- predict(logisModel, newdata=test)
table(test$over50k, logisPredicts > 0.5)
9351 + 1515
10866/12791
library(ROCR)
pred <- prediction(logisPredicts, test$over50k)
as.numeric(performance(predictROC,"auc")@y.values)
as.numeric(performance(pred,"auc")@y.values)
logisPredicts <- predict(logisModel, newdata=test, type="response")
table(test$over50k, logisPredicts >= 0.5)
treeModel <- rpart(over50k ~. , data=train, method="class")
library(rpart)
treeModel <- rpart(over50k ~. , data=train, method="class")
library(rpart.plot)
rpart.plot(treeModel)
treePredicts <- predict(treeModel, newdata=test, type="class")
table(test$over50k, treePredicts > 0.5)
treePredicts
prp(treeModel)
table(test$over50k, treePredicts)
9243+1596
10839/12791
treePred <- prediction(treeModel, test$over50k)
treePredicts <- predict(treeModel, newdata=test)
treePred <- prediction(treePredicts, test$over50k)
treePredicts <- predict(treeModel, newdata=test, type="class")
treePred <- prediction(treePredicts, test$over50k)
treePredicts <- predict(treeModel, newdata=test)
head(treePredicts)
head(treePredicts[2])
head(treePredicts[,2])
treePred <- prediction(treePredicts[,2], test$over50k)
perf = (performance(treePred),"tpr","fpr")
plot(perf)
perf = performance(treePred,"tpr","fpr")
plot(perf)
treePerf = performance(treePred,"tpr","fpr")
logicPerf <- as.numeric(performance(pred,"auc")@y.values)
plot(logicPerf)
logicPerf <- performance(pred,"auc")@y.values
plot(logicPerf)
pred <- prediction(logisPredicts, test$over50k)
logicPerf <- performance(pred,"tpr","fpr")
plot(logicPerf)
as.numeric(performance(treePred, 'auc')@y.values)
set.seed(1)
trainSmall = train[sample(nrow(train), 2000), ]
